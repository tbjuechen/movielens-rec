# 召回阶段负采样技术报告 (Recall Negative Sampling)

在构建 MovieLens 32M 推荐系统时，召回阶段的核心任务是“在大海中捞针”。由于全量电影有 8 万多部，我们无法对每个用户计算所有电影的得分。因此，如何定义“负样本”来训练模型至关重要。

## 1. 为什么需要负采样？
在推荐系统中，我们只有“正样本”（用户看过的电影）。为了让模型学会区分兴趣，我们必须人为构造“负样本”（用户没看过或不感兴趣的电影），告诉模型：“这些是不对的”。

## 2. 三路召回的采样策略

| 召回路 | 采样方式 | 逻辑说明 |
| :--- | :--- | :--- |
| **Popularity** | 无需采样 | 纯统计逻辑，不涉及判别式训练。 |
| **ItemCF** | 无需采样 | 基于物品共现的相似度计算（余弦相似度），不涉及正负样本对。 |
| **Two-Tower** | **In-batch Negative Sampling** | 核心深度学习采样策略。 |

## 3. 双塔模型：In-batch 负采样详解

我们在 `TwoTowerRecall_V2` 中实现了 **In-batch 负采样**。这是目前主流召回系统（如 YouTube DNN, Pinterest）的标准做法。

### 3.1 核心机制
在一个训练批次（Batch）中，假设我们有 $B$ 个用户和他们正在观看的 $B$ 部电影：
- **正样本对**：$(u_1, i_1), (u_2, i_2), \dots, (u_B, i_B)$。
- **负样本构造**：对于用户 $u_1$ 来说，除了电影 $i_1$ 是正样本外，**同 batch 内其他用户正在看的电影 $(i_2, i_3, \dots, i_B)$ 全部被视为 $u_1$ 的负样本**。

### 3.2 数学表达 (InfoNCE Loss)
我们通过内积计算相似度，并使用交叉熵损失：
$$L = -\frac{1}{B} \sum_{i=1}^{B} \log \frac{\exp(u_i \cdot i_i / 	au)}{\sum_{j=1}^{B} \exp(u_i \cdot i_j / 	au)}$$
- **分母**：包含了 Batch 内所有的物品，模拟了全量空间的搜索。
- **$	au$ (Temperature)**：设为 0.07，用于平滑分值，防止梯度爆炸。

### 3.3 策略优势
1. **计算极其高效**：不需要在硬盘上存储海量的负样本，也不需要离线挖掘。
2. **动态更新**：负样本随每个 Batch 的打乱而变化，模型能见识到极其丰富的对比组合。
3. **Batch Size 的红利**：Batch 越大，负样本越多。这就是为什么我们建议在 M4 芯片上使用 **8192** 甚至更大的 Batch。

## 4. 潜在的采样偏差与修正

### 4.1 流行度偏差 (Popularity Bias)
In-batch 采样存在一个天然缺陷：**热门电影出现在 Batch 里的概率更高**。
- 这意味着热门电影被当作负样本的次数更多，模型会倾向于过度打压热门电影。
- **当前状态**：本项目 V2 版本暂未引入“LogQ 修正”，后续可根据评估结果决定是否加入流行度惩罚。

### 4.2 难负样本 (Hard Negatives)
目前所有的负样本都是随机遇到的（Easy Negatives）。
- **下一步规划**：在排序阶段之前的召回优化中，可以引入“召回了但没看”的样本作为 Hard Negatives，强迫模型在相似的物品中做更细微的判别。
